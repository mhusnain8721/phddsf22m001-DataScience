{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"train_new.csv\")\n",
    "#test = pd.read_csv(\"test_new.csv\")\n",
    "#idcol = test['id']\n",
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_y = train[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrow_train = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "#x = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_text = []\n",
    "for i in range(len(train['comment_text'])):\n",
    "    c = train['comment_text'][i]\n",
    "    c= c.lower()\n",
    "    c = c.split()\n",
    "   # ps = PorterStemmer()\n",
    "    c = [stemmer.stem(word) for word in c]\n",
    "    c = ' '.join(c)\n",
    "    corpus_text.append(c)\n",
    "\n",
    "x = corpus_text\n",
    "#stemmer.stem(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer\n",
    "\n",
    "#vect = TfidfVectorizer(max_features=50000, lowercase=True, analyzer='word',stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
    "wordvect = TfidfVectorizer( lowercase=True, analyzer='word',stop_words= 'english', token_pattern=u'(?ui)\\\\b[a-z][a-z][a-z]+\\\\b',\n",
    "                       max_features=100, min_df=2 ,ngram_range=(1,2),dtype=np.float32)\n",
    "\n",
    "#charvect = TfidfVectorizer( lowercase=True, analyzer='char', max_features=30000,ngram_range=(1,5),token_pattern=u'(?ui)\\\\b[a-z][a-z][a-z]+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordfeatures = wordvect.fit(x)\n",
    "#charfeatures = charvect.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36masindices\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0midx_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'comment_text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-f33eb27a6728>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_word_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#test_word_features = wordvect.transform(test['comment_text'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#turain_char_features = charvect.transform(train['comment_text'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#test_char_features = charvect.transform(test['comment_text'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36masindices\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index"
     ]
    }
   ],
   "source": [
    "train_word_features = wordvect.transform(train['comment_text'])\n",
    "#test_word_features = wordvect.transform(test['comment_text'])\n",
    "\n",
    "#turain_char_features = charvect.transform(train['comment_text'])\n",
    "#test_char_features = charvect.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train =  train_word_features\n",
    "#test = test_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred = np.zeros((test.shape[0], len(label_cols)))\n",
    "\n",
    "cv_score =[]\n",
    "for i,col in enumerate(label_cols):\n",
    "    model = LogisticRegression(C=10,random_state = i)\n",
    "    print('Building {} model for column:{''}'.format(i,col)) \n",
    "    model.fit(train,train_y[col])\n",
    "    #cv_score.append(lr.score)\n",
    "    #pred[:,i] = model.predict_proba(test)[:,1]\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(model.score(train, train_y[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn import metrics\n",
    "#pred = np.zeros((test.shape[0], len(label_cols)))\n",
    "#cv_score =[]\n",
    "linestyles = OrderedDict(\n",
    "    [(0,               (0, ())),\n",
    "     (1,      (0, (1, 1))),\n",
    "     (2,      (0, (5, 1))),\n",
    "     (3,          (0, (3, 5, 1, 5))),\n",
    "     (4,  (0, (3, 3, 3, 2))),\n",
    "     (5, (0, (3, 1, 1, 1, 1, 1)))])\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "for i,col in enumerate(label_cols):\n",
    "    print('Building {} model for column:{''}'.format(i,col)) \n",
    "    scores =[]\n",
    "    r_range=(1,11)\n",
    "    for r in r_range:\n",
    "        x_train,x_test,y_train,y_test=train_test_split(train,train_y[col],test_size=0.20,random_state=r)\n",
    "        model = LogisticRegression(C=10,random_state = i)\n",
    "        model.fit(x_train,y_train)\n",
    "        scores.append(model.score(x_test, y_test))\n",
    "        \n",
    "\n",
    "    ax.plot(r_range,scores,linestyle=linestyles[i],label=col)\n",
    "plt.xlabel('Random State for Split')\n",
    "plt.ylabel('Train_Test_Split_Accuracy ')\n",
    "chartBox = ax.get_position()\n",
    "ax.set_position([chartBox.x0, chartBox.y0, chartBox.width*0.6, chartBox.height])\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.45, 0.8), shadow=True, ncol=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

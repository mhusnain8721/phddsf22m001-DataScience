{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"train_new.csv\")\n",
    "test = pd.read_csv(\"test_new.csv\")\n",
    "idcol = test['id']\n",
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.concat([train['comment_text'], test['comment_text']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_y = train[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = df.fillna(\"unknown\")\n",
    "nrow_train = train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5cd44087d355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnowball\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "#x = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_text = []\n",
    "for i in range(len(train['comment_text'])):\n",
    "    c = train['comment_text'][i]\n",
    "    c= c.lower()\n",
    "    c = c.split()\n",
    "   # ps = PorterStemmer()\n",
    "    c = [stemmer.stem(word) for word in c]\n",
    "    c = ' '.join(c)\n",
    "    corpus_text.append(c)\n",
    "\n",
    "x = corpus_text\n",
    "#stemmer.stem(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer\n",
    "\n",
    "#vect = TfidfVectorizer(max_features=50000, lowercase=True, analyzer='word',stop_words= 'english',ngram_range=(1,3),dtype=np.float32)\n",
    "wordvect = TfidfVectorizer( lowercase=True, analyzer='word',stop_words= 'english', token_pattern=u'(?ui)\\\\b[a-z][a-z][a-z]+\\\\b',\n",
    "                       max_features=10000, min_df=2 ,ngram_range=(1,2),dtype=np.float32)\n",
    "\n",
    "#charvect = TfidfVectorizer( lowercase=True, analyzer='char', max_features=30000,ngram_range=(1,5),token_pattern=u'(?ui)\\\\b[a-z][a-z][a-z]+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordfeatures = wordvect.fit(x)\n",
    "#charfeatures = charvect.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_word_features = wordvect.transform(train['comment_text'])\n",
    "test_word_features = wordvect.transform(test['comment_text'])\n",
    "\n",
    "#turain_char_features = charvect.transform(train['comment_text'])\n",
    "#test_char_features = charvect.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train =  train_word_features\n",
    "test = test_word_features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "train_x = hstack([train_char_features, train_word_features])\n",
    "test_x = hstack([test_char_features, test_word_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 0 model for column:toxic\n",
      "Accuracy on training set: 0.962\n",
      "Building 1 model for column:severe_toxic\n",
      "Accuracy on training set: 0.992\n",
      "Building 2 model for column:obscene\n",
      "Accuracy on training set: 0.980\n",
      "Building 3 model for column:threat\n",
      "Accuracy on training set: 0.998\n",
      "Building 4 model for column:insult\n",
      "Accuracy on training set: 0.975\n",
      "Building 5 model for column:identity_hate\n",
      "Accuracy on training set: 0.994\n"
     ]
    }
   ],
   "source": [
    "pred = np.zeros((test.shape[0], len(label_cols)))\n",
    "\n",
    "cv_score =[]\n",
    "for i,col in enumerate(label_cols):\n",
    "    model = LogisticRegression(C=10,random_state = i)\n",
    "    print('Building {} model for column:{''}'.format(i,col)) \n",
    "    model.fit(train,train_y[col])\n",
    "    #cv_score.append(lr.score)\n",
    "    pred[:,i] = model.predict_proba(test)[:,1]\n",
    "    print(\"Accuracy on training set: {:.3f}\".format(model.score(train, train_y[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.947308</td>\n",
       "      <td>0.380705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.016559</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.001579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999944      0.108471  0.999901  0.025119  0.947308   \n",
       "1  0000247867823ef7  0.001244      0.000478  0.000395  0.000396  0.002501   \n",
       "2  00013b17ad220c46  0.016559      0.000705  0.004303  0.000198  0.006815   \n",
       "3  00017563c3f7919a  0.000897      0.001476  0.001018  0.000132  0.002144   \n",
       "4  00017695ad8997eb  0.004431      0.001013  0.001309  0.000838  0.002365   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.380705  \n",
       "1       0.000590  \n",
       "2       0.001579  \n",
       "3       0.000049  \n",
       "4       0.000629  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prd_1 = pd.DataFrame(pred,columns=label_cols)\n",
    "#submit = pd.concat([idcol,prd_1],axis=1)\n",
    "#submit.to_csv('toxic_lr.csv.gz',compression='gzip',index=False)\n",
    "#submit.to_csv('lR_train_tesy.csv',index=False)\n",
    "#submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
